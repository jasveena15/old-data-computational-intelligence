{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","# **SIT215 WEEK 1 Practical (Workshop)**"],"metadata":{"id":"8Wf0YXo93DHn"}},{"cell_type":"markdown","source":["## Agent and Environment\n","\n","Recall our discussed example in Lectures: Vacuum Cleaner\n","\n","Agents and environments provide a useful framework for understanding and designing intelligent systems. By defining agents and environments, we can start to think about the kinds of tasks that an intelligent system might need to perform, the kinds of sensors and actuators it might need to have, and the kinds of knowledge and reasoning it might need to use to make decisions and take actions.\n","\n","We will study a simple vacuum cleaner agent that lives in a simple environment consisting of a n-location room. Each location can either be clean or dirty. The agent can perceive the state of the current location (clean or dirty) and its own location. The agent can perform two actions: `Suck`, which cleans the current location, and `Left` and `Right`, which move the agent to the other location.\n"],"metadata":{"id":"kswBIk0uk4Su"}},{"cell_type":"markdown","source":["### [Discussions]\n","**Questions**\n","1. Study the following example, and figure out how many locations will be created for the agent to react with the environment?\n","\n","[Discussed answer: 25]\n","\n","2. What elements do you identify in the below example implementation for an intelligent system with an agent and environment? What are missing?\n","\n","[Discussed keypoints: Structured program has been established with Constructor for environment initalisation, Perception methods, Action methods, state variables and performance metric method. Details on Action to execute were incomplete in the code to be implemented in the Prac time.]"],"metadata":{"id":"r9Ja2GXyIBNW"}},{"cell_type":"markdown","source":["### [Exercise] Environment - The action method in the below environment does not work. Can you fix it?\n","\n","\n","An environment class may include the following elements:\n","\n","* **Constructor**: initializes the environment's internal state when an instance of the class is created.\n","\n","* **Perception methods**: Perception methods are used by the environment to provide sensory data to agents.\n","\n","* **Action methods**: Action methods are used by agents to perform actions in the environment. These methods might include functions to move the agent or manipulate objects in the environment, or to send messages to other agents.\n","\n","* **State variables**: State variables are used by the environment to keep track of the state of objects and events in the environment.\n","\n","* **Communication methods**: Communication methods are used by the environment to enable agents to interact with each other.\n","\n","* **Performance metrics**: Performance metrics are used to evaluate the effectiveness of agents in achieving their goals. These might include measures of success, such as the agent's score or accuracy, or measures of efficiency, such as the agent's speed or resource utilization.\n","\n","* **Visualisation and rendering methods**: Visualisation and rendering methods are used to display the environment to users. These might include functions to render a 2D or 3D representation of the environment.\n","\n","Overall, an environment class should be designed to provide a rich and dynamic environment for agents to operate in. It should be flexible enough to accommodate a wide range of agent types and behaviors, and should be modular and extensible to allow for easy customization and experimentation.\n"],"metadata":{"id":"Nqa-mlEC7RPB"}},{"cell_type":"code","source":["import random\n","\n","class VacuumEnvironment:\n","    def __init__(self, width, height):\n","        self.width = width\n","        self.height = height\n","        self.agent_location = (random.randint(0, width-1), random.randint(0, height-1))\n","        self.dirt_locations = [(random.randint(0, width-1), random.randint(0, height-1)) for _ in range(random.randint(1, width*height//2))]\n","\n","\n","    def get_percepts(self):\n","        return self.agent_location, self.dirt_locations\n","\n","    def execute_action(self, action):\n","        x, y = self.agent_location\n","        if action == 'left':\n","            self.agent_location =    (max(0, x - 1), y) # moving left\n","        elif action == 'right':\n","            self.agent_location =    (min(self.width - 1, x + 1), y) # moving right\n","        elif action == 'up':\n","            self.agent_location =    (x, max(0, y - 1)) # moving up\n","        elif action == 'down':\n","            self.agent_location =    (x, min(self.height - 1, y + 1))  # moving down\n","        elif action == 'suck' and self.agent_location in self.dirt_locations:\n","            self.dirt_locations.remove(self.agent_location)\n","\n","    def measure_performance(self):\n","        return self.width*self.height - len(self.dirt_locations) * 1 # update the agent's location"],"metadata":{"id":"aO4gN_EY6oP7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example usage\n","env = VacuumEnvironment(5, 5)\n","print(\"Initial Agent Location:\", env.agent_location)\n","print(\"Initial Dirt Locations:\", env.dirt_locations)\n","\n","env.execute_action('left')\n","print(\"Agent Location after moving left:\", env.agent_location)\n","\n","env.execute_action('suck')  # Assuming there's dirt at the new location\n","print(\"Dirt Locations after sucking:\", env.dirt_locations)\n","\n","print(\"Performance Measure:\", env.measure_performance())\n","#"],"metadata":{"id":"04lBW9oY68v3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### [Exercise] Agent\n","\n"],"metadata":{"id":"aAXhu4lT7LEH"}},{"cell_type":"markdown","source":["\n","\n","An agent class may include the following elements:\n","\n","* **Constructor**: A constructor is a special method that initializes the agent's internal state when an instance of the class is created.\n","\n","* **Perception methods**: Perception methods are used by the agent to gather information about its environment. These methods might include functions to read sensory data, to query the state of other agents or objects in the environment, or to receive messages from other agents.\n","\n","* **Decision-making methods**: Decision-making methods are used by the agent to determine its next action based on its current state and any available information. These methods might include search algorithms, reinforcement learning algorithms, or rule-based systems.\n","\n","* **Action methods**: Action methods are used by the agent to perform actions in its environment. These methods might include functions to move the agent or manipulate objects in the environment, or to send messages to other agents.\n","\n","* **Memory or state variables**: Memory or state variables are used by the agent to keep track of its current state and any relevant information. These might include variables to store sensory data, search state, or learned models.\n","\n","* **Communication methods**: Communication methods are used by the agent to interact with other agents in the environment. These might include functions to send or receive messages, or to negotiate with other agents to achieve common goals.\n","\n","* **Performance metrics**: Performance metrics are used to evaluate the agent's effectiveness in achieving its goals. These might include measures of success, such as the agent's score or accuracy, or measures of efficiency, such as the agent's speed or resource utilization.\n","\n","Overall, an agent class should be designed to encapsulate all of the agent's capabilities and responsibilities within a single, well-defined object. This allows the agent to be easily instantiated and reused in multiple environments or scenarios, and makes it easier to debug and maintain the agent's code over time.\n","\n"],"metadata":{"id":"k8M6NpfQXLDP"}},{"cell_type":"markdown","source":["#### [Discussions]\n","**Questions**\n","\n","1. What methods are in an `agent` class but not in an `environment` class?\n","\n","[Discussed point(s): Choose Action (/Action Selection) is from agent class]\n","\n","2. How is an action method in an environment class different from an action method in an agent class?\n","\n","[Discussed point(s):\n","\n","* Action Method in an Environment Class: Executes the effects of the agent's actions within the environment. Does not decide what action to perform. It implements the consequences of actions chosen by the agent.\n","\n","* Action Method in an Agent Class: Determines what action the agent should take next, based on its goals, knowledge, and perceptions of the environment.\n","Sends a command to the environment to execute this action but does not directly manipulate the environment's state.\n","\n","]"],"metadata":{"id":"N5UJkPLgEm2e"}},{"cell_type":"markdown","source":["#### Model-based Reflex Agents\n","\n","We can add internal state to obtain model-based reflex agents. Its current state is a model of the environment and it updates that state based on the actions it takes and the percepts it receives.\n"],"metadata":{"id":"Fh_BlpXPHIF9"}},{"cell_type":"markdown","source":["##### [Exercise] Study the below example and fix the data structure that induced the error."],"metadata":{"id":"BF3dW0dRDUcD"}},{"cell_type":"code","source":["class ModelBasedReflexVacuumAgent:\n","    def __init__(self, environment):\n","        self.environment = environment\n","        self.state = self.get_percept()\n","\n","    def get_percept(self):\n","        location, dirt_locations = self.environment.get_percepts()\n","        return {'location': location, 'dirt_locations': set(dirt_locations)}\n","\n","    def update_state(self, action, percept):\n","        location, dirt_locations = self.state['location'], self.state['dirt_locations']\n","\n","        if action == 'suck':\n","            dirt_locations.discard(location)\n","        elif action == 'up':\n","            location = (location[0], location[1] - 1)\n","        elif action == 'down':\n","            location = (location[0], location[1] + 1)\n","        elif action == 'left':\n","            location = (location[0] - 1, location[1])\n","        elif action == 'right':\n","            location = (location[0] + 1, location[1])\n","\n","        dirt_locations.update(percept['dirt_locations'])\n","\n","        self.state = {'location': location, 'dirt_locations': dirt_locations}\n","\n","    def choose_action(self):\n","        location, dirt_locations = self.state['location'], self.state['dirt_locations']\n","        if location in dirt_locations:\n","            return 'suck'\n","        else:\n","            x, y = location\n","            if x == 0:\n","                return 'right'\n","            elif x == self.environment.width - 1:\n","                return  'left'\n","            elif y == 0:\n","                return  'down'\n","            elif y == self.environment.height - 1:\n","                return 'up'\n","            else:\n","                return random.choice(['up', 'down', 'left', 'right'])\n","\n","\n","env = VacuumEnvironment(5, 5)\n","\n","agent = ModelBasedReflexVacuumAgent(env)\n","\n","for i in range(10):\n","    percept = agent.get_percept()\n","    print('Percept:', percept)\n","    action = agent.choose_action()\n","    agent.choose_action()\n","    agent.update_state(action,percept)\n","    env.execute_action(action)\n","    print('Action:', action)\n","    print('Performance:', env.measure_performance())"],"metadata":{"id":"uBxVCaMoHvQM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### [Discussions]\n","**Questions**\n","1. In the given `ModelBasedReflexVacuumAgent`, what constitutes the `internal state (self.state)`?\n","\n","[ Discussed point(s): Agent’s Current Location (location) and Dirt Locations (dirt_locations)]\n","\n","2. How does the `agent` perceive the `environment` and update its internal state??\n","\n","[ Discussed point(s): `get_percept()` It captures: The current location of the agent, and the set of dirt locations detected at that moment. `update_state(action, percept) modifies stored Knowledge` updates the internal state (self.state) based on the agent’s actions and new perceptions. `choose_action()` relies on the stored internal state to decide the best move.]\n"],"metadata":{"id":"tdUYt8IWCtC5"}},{"cell_type":"markdown","source":["### Additional readings\n","\n","- [Intelligent Agents](https://github.com/aimacode/aima-python/blob/master/agents.ipynb)\n","- [Python list implementation](http://www.laurentluce.com/posts/python-list-implementation/)\n"],"metadata":{"id":"CKgYkfHPQiKr"}},{"cell_type":"markdown","source":["## [Your after-class Exercise]\n","\n","1. Review your class discussions and take notes/code comments on the above-mentioned examples to consolidate your understanding."],"metadata":{"id":"kRGwn9oYLvzQ"}}]}